{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do: \n",
    "- do we really want to calculate the delta index? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: \n",
      "../data/original/client_train.csv\n",
      "../data/original/invoice_train.csv\n",
      "../data/original/client_test.csv\n",
      "../data/original/invoice_test.csv\n",
      "...\n",
      "Finished loading data.\n",
      "------------------------------\n",
      "Engineering features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 220\u001b[0m\n\u001b[1;32m    217\u001b[0m file_client_test \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/original/client_test.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    218\u001b[0m file_invoice_test \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/original/invoice_test.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 220\u001b[0m main(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\n",
      "Cell \u001b[0;32mIn[3], line 163\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m# feature engineering\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEngineering features...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m client_train, invoice_train_agg, client_test, invoice_test_agg \u001b[39m=\u001b[39m feature_engineering(client_train, invoice_train, client_test, invoice_test)\n\u001b[1;32m    164\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinished engineering features...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 83\u001b[0m, in \u001b[0;36mfeature_engineering\u001b[0;34m(client_train, invoice_train, client_test, invoice_test)\u001b[0m\n\u001b[1;32m     80\u001b[0m invoice_train \u001b[39m=\u001b[39m invoice_train\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39minvoice_date.dt.year >= 2005\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[1;32m     82\u001b[0m \u001b[39m# aggregating invoice data by client_id \u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m invoice_train_agg \u001b[39m=\u001b[39m aggregate_by_client_id(invoice_train)\n\u001b[1;32m     84\u001b[0m invoice_test_agg \u001b[39m=\u001b[39m aggregate_by_client_id(invoice_test)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m client_train, invoice_train_agg, client_test, invoice_test_agg\n",
      "Cell \u001b[0;32mIn[3], line 114\u001b[0m, in \u001b[0;36maggregate_by_client_id\u001b[0;34m(invoice_data)\u001b[0m\n\u001b[1;32m    111\u001b[0m aggs[\u001b[39m'\u001b[39m\u001b[39mmonths_number\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    112\u001b[0m aggs[\u001b[39m'\u001b[39m\u001b[39mcounter_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [pd\u001b[39m.\u001b[39mSeries\u001b[39m.\u001b[39mmode]\n\u001b[0;32m--> 114\u001b[0m agg_trans \u001b[39m=\u001b[39m invoice_data\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mclient_id\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49magg(aggs)\n\u001b[1;32m    115\u001b[0m agg_trans\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(col)\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m agg_trans\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mvalues]\n\u001b[1;32m    116\u001b[0m agg_trans\u001b[39m.\u001b[39mreset_index(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:979\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    978\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 979\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m    980\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/apply.py:161\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    162\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    163\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/apply.py:435\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[1;32m    436\u001b[0m         key: obj\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    437\u001b[0m     }\n\u001b[1;32m    439\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    440\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/apply.py:436\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    432\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    433\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 436\u001b[0m         key: obj\u001b[39m.\u001b[39;49m_gotitem(key, ndim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    437\u001b[0m     }\n\u001b[1;32m    439\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    440\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:249\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, abc\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m    246\u001b[0m     \u001b[39m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[39m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 249\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_multiple_funcs(func)\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m relabeling:\n\u001b[1;32m    251\u001b[0m         \u001b[39m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[39m# \"Optional[List[str]]\", variable has type \"Index\")\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         ret\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m columns  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:303\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mfor\u001b[39;00m idx, (name, func) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arg):\n\u001b[1;32m    302\u001b[0m     key \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mOutputKey(label\u001b[39m=\u001b[39mname, position\u001b[39m=\u001b[39midx)\n\u001b[0;32m--> 303\u001b[0m     results[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(func)\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, DataFrame) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    306\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:265\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_agg_general(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    266\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# TODO: KeyError is raised in _python_agg_general,\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39m#  see test_groupby.test_basic\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_named(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1332\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1328\u001b[0m name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mname\n\u001b[1;32m   1330\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# if this function is invalid for this dtype, we will ignore it.\u001b[39;00m\n\u001b[0;32m-> 1332\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(obj, f)\n\u001b[1;32m   1333\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1334\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1335\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDropping invalid columns in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.agg \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1336\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis deprecated. In a future version, a TypeError will be raised. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m   1341\u001b[0m     )\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/ops.py:1060\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m   1059\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_fast(obj, func)\n\u001b[1;32m   1062\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1063\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/ops.py:1085\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_fast\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1083\u001b[0m ids \u001b[39m=\u001b[39m ids\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   1084\u001b[0m sgrouper \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mSeriesGrouper(obj, func, ids, ngroups)\n\u001b[0;32m-> 1085\u001b[0m result, _ \u001b[39m=\u001b[39m sgrouper\u001b[39m.\u001b[39;49mget_result()\n\u001b[1;32m   1086\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/_libs/reduction.pyx:281\u001b[0m, in \u001b[0;36mpandas._libs.reduction.SeriesGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/_libs/reduction.pyx:88\u001b[0m, in \u001b[0;36mpandas._libs.reduction._BaseGrouper._apply_to_group\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1318\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_agg_general\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1317\u001b[0m     func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mis_builtin_func(func)\n\u001b[0;32m-> 1318\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1320\u001b[0m     \u001b[39m# iterate through \"columns\" ex exclusions to populate output dict\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     output: \u001b[39mdict\u001b[39m[base\u001b[39m.\u001b[39mOutputKey, ArrayLike] \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/series.py:1979\u001b[0m, in \u001b[0;36mSeries.mode\u001b[0;34m(self, dropna)\u001b[0m\n\u001b[1;32m   1961\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1962\u001b[0m \u001b[39mReturn the mode(s) of the Series.\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m \u001b[39m    Modes of the Series in sorted order.\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m \u001b[39m# TODO: Add option for bins like value_counts()\u001b[39;00m\n\u001b[0;32m-> 1979\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmode(\u001b[39mself\u001b[39;49m, dropna\u001b[39m=\u001b[39;49mdropna)\n",
      "File \u001b[0;32m~/neuefische/MLproject/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:965\u001b[0m, in \u001b[0;36mmode\u001b[0;34m(values, dropna)\u001b[0m\n\u001b[1;32m    961\u001b[0m     values \u001b[39m=\u001b[39m values[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m    963\u001b[0m values, _ \u001b[39m=\u001b[39m _ensure_data(values)\n\u001b[0;32m--> 965\u001b[0m npresult \u001b[39m=\u001b[39m htable\u001b[39m.\u001b[39;49mmode(values, dropna\u001b[39m=\u001b[39;49mdropna)\n\u001b[1;32m    966\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    967\u001b[0m     npresult \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(npresult)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import all neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# for grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# function to load .csv client and invoice data tables each for train and test data\n",
    "def load_data(file_client_train, file_invoice_train, file_client_test, file_invoice_test): \n",
    "    \"\"\"loads .csv client and invoice data tables each for train and test data\n",
    "\n",
    "    Args:\n",
    "        file_client_train (str): path to client train data table, e.g. 'data/original/client_train.csv'\n",
    "        file_invoice_train (str): path to invoice train data table, e.g. 'data/original/invoice_train.csv'\n",
    "        file_client_test (str): path to client test data table, e.g. 'data/original/client_test.csv'\n",
    "        file_invoice_test (str): path to invoice test data table, e.g. 'data/original/invoice_test.csv'\n",
    "\n",
    "    Returns:\n",
    "        dataframes: client_train, invoice_train, client_test, invoice_test\n",
    "    \"\"\"\n",
    "\n",
    "    # read client and invoice data tables for each train and test data from .csv to pandas DataFrame\n",
    "    client_train = pd.read_csv(file_client_train, low_memory=False)\n",
    "    invoice_train = pd.read_csv(file_invoice_train, low_memory=False)\n",
    "    client_test = pd.read_csv(file_client_test, low_memory=False)\n",
    "    invoice_test = pd.read_csv(file_invoice_test, low_memory=False)\n",
    "\n",
    "    return client_train, invoice_train, client_test, invoice_test\n",
    "\n",
    "\n",
    "# function for datetime conversion, one-hot encoding, calculating delta index, removing data from before 2005\n",
    "def feature_engineering(client_train, invoice_train, client_test, invoice_test): \n",
    "    \"\"\"datetime conversion, one-hot encoding, calculate delta index and remove data from before 2005\n",
    "\n",
    "    Args:\n",
    "        client_train (dataframe): _description_\n",
    "        invoice_train_agg (dataframe): _description_\n",
    "        client_test (dataframe): _description_\n",
    "        invoice_test_agg (dataframe): _description_\n",
    "\n",
    "    Returns:\n",
    "        dataframes: client_train, invoice_train_agg, client_test, invoice_test_agg\n",
    "    \"\"\"\n",
    "\n",
    "    #convert the column invoice_date to date time format on both the invoice train and invoice test\n",
    "    for df in [invoice_train,invoice_test]:\n",
    "        df['invoice_date'] = pd.to_datetime(df['invoice_date'])\n",
    "\n",
    "    # one-hot encode labels in categorical column\n",
    "    d={\"ELEC\":0,\"GAZ\":1}\n",
    "    invoice_train['counter_type']=invoice_train['counter_type'].map(d)\n",
    "    invoice_test['counter_type']=invoice_test['counter_type'].map(d)\n",
    "\n",
    "    #convert categorical columns to int for model\n",
    "    #client_train['client_catg'] = client_train['client_catg'].astype(int)\n",
    "    #client_train['disrict'] = client_train['disrict'].astype(int)\n",
    "\n",
    "    #client_test['client_catg'] = client_test['client_catg'].astype(int)\n",
    "    #client_test['disrict'] = client_test['disrict'].astype(int)\n",
    "\n",
    "    # calculate delta index as the difference between new_index and old_index\n",
    "    invoice_train['delta_index'] = invoice_train.new_index - invoice_train.old_index\n",
    "    invoice_train.drop(['old_index', 'new_index'], axis=1, inplace=True)\n",
    "\n",
    "    invoice_test['delta_index'] = invoice_test.new_index - invoice_test.old_index\n",
    "    invoice_test.drop(['old_index', 'new_index'], axis=1, inplace=True)\n",
    "\n",
    "    # remove all invoices before 2005 as there were no frauds detected / documented\n",
    "    invoice_train = invoice_train.query('invoice_date.dt.year >= 2005') \n",
    "\n",
    "    # aggregating invoice data by client_id \n",
    "    invoice_train_agg = aggregate_by_client_id(invoice_train)\n",
    "    invoice_test_agg = aggregate_by_client_id(invoice_test)\n",
    "\n",
    "    return client_train, invoice_train_agg, client_test, invoice_test_agg\n",
    "\n",
    "\n",
    "# function for aggregating invoice data\n",
    "def aggregate_by_client_id(invoice_data):\n",
    "    \"\"\"aggregating invoice data by client_id by taking mean (num) or mode (object)\n",
    "\n",
    "    Args:\n",
    "        invoice_data (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    aggs = {}\n",
    "    aggs['consommation_level_1'] = ['mean']\n",
    "    aggs['consommation_level_2'] = ['mean']\n",
    "    aggs['consommation_level_3'] = ['mean']\n",
    "    aggs['consommation_level_4'] = ['mean']\n",
    "    aggs['tarif_type'] = ['mean']\n",
    "    aggs['counter_number'] = ['mean']\n",
    "    aggs['counter_statue'] = [pd.Series.mode]\n",
    "    aggs['counter_code'] = ['mean']\n",
    "    aggs['reading_remarque'] = ['mean']\n",
    "    aggs['counter_coefficient'] = ['mean']\n",
    "    aggs['delta_index'] = ['mean']\n",
    "    aggs['months_number'] = ['mean']\n",
    "    aggs['counter_type'] = [pd.Series.mode]\n",
    "\n",
    "    agg_trans = invoice_data.groupby(['client_id']).agg(aggs)\n",
    "    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = (invoice_data.groupby('client_id')\n",
    "            .size()\n",
    "            .reset_index(name='{}transactions_count'.format('1')))\n",
    "    return pd.merge(df, agg_trans, on='client_id', how='left')\n",
    "\n",
    "\n",
    "# function to drop redundant columns\n",
    "def drop_redundant_columns(train, test): \n",
    "    \"\"\"drop redudant columns\n",
    "\n",
    "    Args:\n",
    "        train (dataframe): merged train data from clients and invoices\n",
    "        test (dataframe): merged test data from clients and invoices\n",
    "    \"\"\"\n",
    "    #drop redundant columns\n",
    "    sub_client_id = test['client_id']\n",
    "    drop_columns = ['client_id', 'creation_date']\n",
    "\n",
    "    for col in drop_columns:\n",
    "        if col in train.columns:\n",
    "            train.drop([col], axis=1, inplace=True)\n",
    "        if col in test.columns:\n",
    "            test.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# main function \n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "def main(file_client_train, file_invoice_train, file_client_test, file_invoice_test):\n",
    "\n",
    "    # load data\n",
    "    print('Loading data from: ')\n",
    "    print(str(file_client_train) + '\\n' + str(file_invoice_train) + '\\n' + str(file_client_test) + '\\n' + str(file_invoice_test))\n",
    "    print('...')\n",
    "    client_train, invoice_train, client_test, invoice_test = load_data(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\n",
    "    print('Finished loading data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # feature engineering\n",
    "    print('Engineering features...')\n",
    "    client_train, invoice_train_agg, client_test, invoice_test_agg = feature_engineering(client_train, invoice_train, client_test, invoice_test)\n",
    "    print('Finished engineering features...')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # left join invoice to client table\n",
    "    print('Merging client and invoice data... ')\n",
    "    train = pd.merge(client_train, invoice_train_agg, on='client_id', how='left')\n",
    "    test = pd.merge(client_test, invoice_test_agg, on='client_id', how='left')\n",
    "    print('Finishe merging client and invoice data... ')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # drop redundant columns\n",
    "    print('Dropping redundant columns in dataframes...')\n",
    "    train, test = drop_redundant_columns(train, test)\n",
    "    print('Finished dropping redundant columns in dataframes. ')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Final training data cleaning \n",
    "    print('Final cleaning of the training data...')\n",
    "    train.drop(['counter_type_mode', 'counter_statue_mode'], axis=1, inplace=True)\n",
    "    train.dropna(axis=0, inplace=True)\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print('Finished final cleaning of the training data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Splitting training data \n",
    "    print('Preparing (splitting) training data for model building...')\n",
    "    X = train.drop('target', axis=1)\n",
    "    y = train.target\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) \n",
    "    print('Finished preparing (splitting) training data for model building.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Fitting final XGB model to train data\n",
    "    print('Building best XGB model on training data...')\n",
    "    model = XGBClassifier(max_depth = 5, learning_rate = 0.3, \n",
    "                        subsample = 0.7999999999999999, colsample_bytree = 0.8999999999999999, colsample_bylevel = 0.4, \n",
    "                        n_estimators = 500)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Finished building best XGB model on training data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Predicting with final XGB model\n",
    "    print('Predicting targets (fraud clients) from test data...')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Finished predicting targets (fraud clients) from test data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Save prediction to .csv file\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_client_train = sys.argv[1]\n",
    "    file_invoice_train = sys.argv[2]\n",
    "    file_client_test = sys.argv[3]\n",
    "    file_invoice_test = sys.argv[4]\n",
    "\n",
    "    main(file_client_train, file_invoice_train, file_client_test, file_invoice_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2221699215.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[90], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if __name__ == '__main__':\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def main(arguments):\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main(sys.argv[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97     24160\n",
      "         1.0       0.52      0.15      0.24      1513\n",
      "\n",
      "    accuracy                           0.94     25673\n",
      "   macro avg       0.73      0.57      0.60     25673\n",
      "weighted avg       0.92      0.94      0.93     25673\n",
      " [[23943   217]\n",
      " [ 1281   232]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred), cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-o OUTFILE] infile\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "def main(arguments):\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "    parser.add_argument('infile', help=\"Input file\", type=argparse.FileType('r'))\n",
    "    parser.add_argument('-o', '--outfile', help=\"Output file\",\n",
    "                        default=sys.stdout, type=argparse.FileType('w'))\n",
    "\n",
    "    args = parser.parse_args(arguments)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.exit(main(sys.argv[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_client_train = '../data/original/client_train.csv'\n",
    "file_invoice_train = '../data/original/invoice_train.csv'\n",
    "file_client_test = '../data/original/client_test.csv'\n",
    "file_invoice_test = '../data/original/invoice_test.csv'\n",
    "client_train, invoice_train, client_test, invoice_test = load_data(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
