{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do: \n",
    "- do we really want to calculate the delta index? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all neccessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for XGBoost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# for grid search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# function to load .csv client and invoice data tables each for train and test data\n",
    "def load_data(file_client_train, file_invoice_train, file_client_test, file_invoice_test): \n",
    "    \"\"\"loads .csv client and invoice data tables each for train and test data\n",
    "\n",
    "    Args:\n",
    "        file_client_train (str): path to client train data table, e.g. 'data/original/client_train.csv'\n",
    "        file_invoice_train (str): path to invoice train data table, e.g. 'data/original/invoice_train.csv'\n",
    "        file_client_test (str): path to client test data table, e.g. 'data/original/client_test.csv'\n",
    "        file_invoice_test (str): path to invoice test data table, e.g. 'data/original/invoice_test.csv'\n",
    "\n",
    "    Returns:\n",
    "        dataframes: client_train, invoice_train, client_test, invoice_test\n",
    "    \"\"\"\n",
    "\n",
    "    # read client and invoice data tables for each train and test data from .csv to pandas DataFrame\n",
    "    client_train = pd.read_csv(file_client_train, low_memory=False)\n",
    "    invoice_train = pd.read_csv(file_invoice_train, low_memory=False)\n",
    "    client_test = pd.read_csv(file_client_test, low_memory=False)\n",
    "    invoice_test = pd.read_csv(file_invoice_test, low_memory=False)\n",
    "\n",
    "    return client_train, invoice_train, client_test, invoice_test\n",
    "\n",
    "\n",
    "# function for datetime conversion, one-hot encoding, calculating delta index, removing data from before 2005\n",
    "def feature_engineering(client_train, invoice_train, client_test, invoice_test): \n",
    "    \"\"\"datetime conversion, one-hot encoding, calculate delta index and remove data from before 2005\n",
    "\n",
    "    Args:\n",
    "        client_train (dataframe): _description_\n",
    "        invoice_train_agg (dataframe): _description_\n",
    "        client_test (dataframe): _description_\n",
    "        invoice_test_agg (dataframe): _description_\n",
    "\n",
    "    Returns:\n",
    "        dataframes: client_train, invoice_train_agg, client_test, invoice_test_agg\n",
    "    \"\"\"\n",
    "\n",
    "    #convert the column invoice_date to date time format on both the invoice train and invoice test\n",
    "    for df in [invoice_train,invoice_test]:\n",
    "        df['invoice_date'] = pd.to_datetime(df['invoice_date'])\n",
    "\n",
    "    # one-hot encode labels in categorical column\n",
    "    d={\"ELEC\":0,\"GAZ\":1}\n",
    "    invoice_train['counter_type']=invoice_train['counter_type'].map(d)\n",
    "    invoice_test['counter_type']=invoice_test['counter_type'].map(d)\n",
    "\n",
    "    #convert categorical columns to int for model\n",
    "    #client_train['client_catg'] = client_train['client_catg'].astype(int)\n",
    "    #client_train['disrict'] = client_train['disrict'].astype(int)\n",
    "\n",
    "    #client_test['client_catg'] = client_test['client_catg'].astype(int)\n",
    "    #client_test['disrict'] = client_test['disrict'].astype(int)\n",
    "\n",
    "    # calculate delta index as the difference between new_index and old_index\n",
    "    invoice_train['delta_index'] = invoice_train.new_index - invoice_train.old_index\n",
    "    invoice_train.drop(['old_index', 'new_index'], axis=1, inplace=True)\n",
    "\n",
    "    invoice_test['delta_index'] = invoice_test.new_index - invoice_test.old_index\n",
    "    invoice_test.drop(['old_index', 'new_index'], axis=1, inplace=True)\n",
    "\n",
    "    # remove all invoices before 2005 as there were no frauds detected / documented\n",
    "    invoice_train = invoice_train.query('invoice_date.dt.year >= 2005') \n",
    "\n",
    "    # aggregating invoice data by client_id \n",
    "    invoice_train_agg = aggregate_by_client_id(invoice_train)\n",
    "    invoice_test_agg = aggregate_by_client_id(invoice_test)\n",
    "\n",
    "    return client_train, invoice_train_agg, client_test, invoice_test_agg\n",
    "\n",
    "\n",
    "# function for aggregating invoice data\n",
    "def aggregate_by_client_id(invoice_data):\n",
    "    \"\"\"aggregating invoice data by client_id by taking mean (num) or mode (object)\n",
    "\n",
    "    Args:\n",
    "        invoice_data (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    aggs = {}\n",
    "    aggs['consommation_level_1'] = ['mean']\n",
    "    aggs['consommation_level_2'] = ['mean']\n",
    "    aggs['consommation_level_3'] = ['mean']\n",
    "    aggs['consommation_level_4'] = ['mean']\n",
    "    aggs['tarif_type'] = ['mean']\n",
    "    aggs['counter_number'] = ['mean']\n",
    "    aggs['counter_statue'] = [pd.Series.mode]\n",
    "    aggs['counter_code'] = ['mean']\n",
    "    aggs['reading_remarque'] = ['mean']\n",
    "    aggs['counter_coefficient'] = ['mean']\n",
    "    aggs['delta_index'] = ['mean']\n",
    "    aggs['months_number'] = ['mean']\n",
    "    aggs['counter_type'] = [pd.Series.mode]\n",
    "\n",
    "    agg_trans = invoice_data.groupby(['client_id']).agg(aggs)\n",
    "    agg_trans.columns = ['_'.join(col).strip() for col in agg_trans.columns.values]\n",
    "    agg_trans.reset_index(inplace=True)\n",
    "\n",
    "    df = (invoice_data.groupby('client_id')\n",
    "            .size()\n",
    "            .reset_index(name='{}transactions_count'.format('1')))\n",
    "    return pd.merge(df, agg_trans, on='client_id', how='left')\n",
    "\n",
    "\n",
    "# function to drop redundant columns\n",
    "def drop_redundant_columns(train, test): \n",
    "    \"\"\"drop redudant columns\n",
    "\n",
    "    Args:\n",
    "        train (dataframe): merged train data from clients and invoices\n",
    "        test (dataframe): merged test data from clients and invoices\n",
    "    \"\"\"\n",
    "    #drop redundant columns\n",
    "    sub_client_id = test['client_id']\n",
    "    drop_columns = ['client_id', 'creation_date']\n",
    "\n",
    "    for col in drop_columns:\n",
    "        if col in train.columns:\n",
    "            train.drop([col], axis=1, inplace=True)\n",
    "        if col in test.columns:\n",
    "            test.drop([col], axis=1, inplace=True)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# main function \n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "def main(file_client_train, file_invoice_train, file_client_test, file_invoice_test):\n",
    "\n",
    "    # load data\n",
    "    print('Loading data from: ')\n",
    "    print(str(file_client_train) + '\\n' + str(file_invoice_train) + '\\n' + str(file_client_test) + '\\n' + str(file_invoice_test))\n",
    "    print('...')\n",
    "    client_train, invoice_train, client_test, invoice_test = load_data(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\n",
    "    print('Finished loading data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # feature engineering\n",
    "    print('Engineering features...')\n",
    "    client_train, invoice_train_agg, client_test, invoice_test_agg = feature_engineering(client_train, invoice_train, client_test, invoice_test)\n",
    "    print('Finished engineering features...')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # left join invoice to client table\n",
    "    print('Merging client and invoice data... ')\n",
    "    train = pd.merge(client_train, invoice_train_agg, on='client_id', how='left')\n",
    "    test = pd.merge(client_test, invoice_test_agg, on='client_id', how='left')\n",
    "    print('Finishe merging client and invoice data... ')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # drop redundant columns\n",
    "    print('Dropping redundant columns in dataframes...')\n",
    "    train, test = drop_redundant_columns(train, test)\n",
    "    print('Finished dropping redundant columns in dataframes. ')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Final training data cleaning \n",
    "    print('Final cleaning of the training data...')\n",
    "    train.drop(['counter_type_mode', 'counter_statue_mode'], axis=1, inplace=True)\n",
    "    train.dropna(axis=0, inplace=True)\n",
    "    train.drop_duplicates(inplace=True)\n",
    "    print('Finished final cleaning of the training data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Splitting training data \n",
    "    print('Preparing (splitting) training data for model building...')\n",
    "    X = train.drop('target', axis=1)\n",
    "    y = train.target\n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) \n",
    "    print('Finished preparing (splitting) training data for model building.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Fitting final XGB model to train data\n",
    "    print('Building best XGB model on training data...')\n",
    "    model = XGBClassifier(max_depth = 5, learning_rate = 0.3, \n",
    "                        subsample = 0.7999999999999999, colsample_bytree = 0.8999999999999999, colsample_bylevel = 0.4, \n",
    "                        n_estimators = 500)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Finished building best XGB model on training data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Predicting with final XGB model\n",
    "    print('Predicting targets (fraud clients) from test data...')\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Finished predicting targets (fraud clients) from test data.')\n",
    "    print('------------------------------')\n",
    "\n",
    "    # Save prediction to .csv file\n",
    "    import pickle\n",
    "    # save the model to disk\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_client_train = sys.argv[1]\n",
    "    file_invoice_train = sys.argv[2]\n",
    "    file_client_test = sys.argv[3]\n",
    "    file_invoice_test = sys.argv[4]\n",
    "\n",
    "    main(file_client_train, file_invoice_train, file_client_test, file_invoice_test)\n",
    "\n",
    "\n",
    "# python python_script/predict_frauds.py ./data/original/client_train.csv ./data/original/invoice_train.csv ./data/original/client_test.csv ./data/original/invoice_test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
